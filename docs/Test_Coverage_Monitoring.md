# LingShué¡¹ç›® - æµ‹è¯•è¦†ç›–ç‡ç›‘æ§ä¸è´¨é‡åº¦é‡æ–¹æ¡ˆ

## 1. æµ‹è¯•è¦†ç›–ç‡ç›‘æ§ä½“ç³»

### 1.1 è¦†ç›–ç‡ç›®æ ‡è®¾å®š

#### 1.1.1 åˆ†å±‚è¦†ç›–ç‡ç›®æ ‡
```
æ•´ä½“é¡¹ç›®è¦†ç›–ç‡: â‰¥80%
â”œâ”€â”€ é¢†åŸŸå±‚ (Domain Layer): â‰¥95%     # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼Œå¿…é¡»é«˜è¦†ç›–
â”œâ”€â”€ åº”ç”¨å±‚ (Application Layer): â‰¥90% # ä¸šåŠ¡æµç¨‹ç¼–æ’ï¼Œé‡è¦åº¦é«˜
â”œâ”€â”€ APIå±‚ (API Layer): â‰¥85%          # æ¥å£å±‚ï¼Œéœ€è¦å……åˆ†æµ‹è¯•
â””â”€â”€ åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer): â‰¥70% # æŠ€æœ¯å®ç°ï¼Œé€‚åº¦è¦†ç›–
```

#### 1.1.2 è¦†ç›–ç‡è´¨é‡ç­‰çº§
```
ä¼˜ç§€: â‰¥90%   ğŸŸ¢ ç»¿è‰²çŠ¶æ€
è‰¯å¥½: 80-89% ğŸŸ¡ é»„è‰²çŠ¶æ€  
åŠæ ¼: 70-79% ğŸŸ  æ©™è‰²çŠ¶æ€
ä¸åŠæ ¼: <70% ğŸ”´ çº¢è‰²çŠ¶æ€
```

### 1.2 è¦†ç›–ç‡å·¥å…·é…ç½®

#### 1.2.1 Coverage.pyé…ç½®
```toml
# pyproject.toml
[tool.coverage.run]
source = ["app"]
omit = [
    "*/tests/*",
    "*/migrations/*",
    "*/__pycache__/*",
    "*/venv/*",
    "app/main.py",  # åº”ç”¨å…¥å£ï¼Œé€šå¸¸ä¸éœ€è¦å•å…ƒæµ‹è¯•
]
branch = true
parallel = true

[tool.coverage.report]
show_missing = true
skip_covered = false
skip_empty = false
precision = 2
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "@abstract",
]

[tool.coverage.html]
directory = "htmlcov"
title = "LingShu Coverage Report"

[tool.coverage.xml]
output = "coverage.xml"

[tool.coverage.json]
output = "coverage.json"
```

#### 1.2.2 Pytesté…ç½®
```toml
# pyproject.toml
[tool.pytest.ini_options]
minversion = "7.0"
addopts = [
    "--cov=app",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-report=xml",
    "--cov-report=json",
    "--cov-branch",
    "--cov-fail-under=80",
    "--strict-markers",
    "--strict-config",
    "-ra",
    "--tb=short",
]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
markers = [
    "unit: Unit tests",
    "integration: Integration tests", 
    "e2e: End-to-end tests",
    "slow: Slow running tests",
    "external: Tests requiring external services",
]
```

### 1.3 è¦†ç›–ç‡ç›‘æ§è„šæœ¬

#### 1.3.1 è¦†ç›–ç‡æ£€æŸ¥è„šæœ¬
```python
# scripts/coverage_monitor.py
import json
import sys
import argparse
from pathlib import Path
from typing import Dict, List, NamedTuple
from dataclasses import dataclass
from datetime import datetime

@dataclass
class CoverageResult:
    """è¦†ç›–ç‡ç»“æœ"""
    file_path: str
    line_coverage: float
    branch_coverage: float
    missing_lines: List[int]
    total_lines: int
    covered_lines: int

class CoverageThreshold(NamedTuple):
    """è¦†ç›–ç‡é˜ˆå€¼"""
    layer: str
    min_coverage: float
    files_pattern: str

class CoverageMonitor:
    """è¦†ç›–ç‡ç›‘æ§å™¨"""
    
    # åˆ†å±‚è¦†ç›–ç‡é˜ˆå€¼é…ç½®
    LAYER_THRESHOLDS = [
        CoverageThreshold("domain", 95.0, "app/domain/**/*.py"),
        CoverageThreshold("application", 90.0, "app/application/**/*.py"),  
        CoverageThreshold("api", 85.0, "app/api/**/*.py"),
        CoverageThreshold("infrastructure", 70.0, "app/infrastructure/**/*.py"),
    ]
    
    def __init__(self, coverage_file: str = "coverage.json"):
        self.coverage_file = coverage_file
        self.coverage_data = self._load_coverage_data()
    
    def _load_coverage_data(self) -> Dict:
        """åŠ è½½è¦†ç›–ç‡æ•°æ®"""
        try:
            with open(self.coverage_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ è¦†ç›–ç‡æ–‡ä»¶ {self.coverage_file} ä¸å­˜åœ¨")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ è¦†ç›–ç‡æ–‡ä»¶ {self.coverage_file} æ ¼å¼é”™è¯¯")
            sys.exit(1)
    
    def get_overall_coverage(self) -> float:
        """è·å–æ•´ä½“è¦†ç›–ç‡"""
        totals = self.coverage_data.get('totals', {})
        return totals.get('percent_covered', 0.0)
    
    def get_file_coverage(self, file_path: str) -> CoverageResult:
        """è·å–å•ä¸ªæ–‡ä»¶çš„è¦†ç›–ç‡"""
        files = self.coverage_data.get('files', {})
        file_data = files.get(file_path, {})
        
        summary = file_data.get('summary', {})
        
        return CoverageResult(
            file_path=file_path,
            line_coverage=summary.get('percent_covered', 0.0),
            branch_coverage=summary.get('percent_covered_display', 0.0),
            missing_lines=file_data.get('missing_lines', []),
            total_lines=summary.get('num_statements', 0),
            covered_lines=summary.get('covered_lines', 0)
        )
    
    def check_layer_coverage(self, layer_threshold: CoverageThreshold) -> bool:
        """æ£€æŸ¥ç‰¹å®šå±‚çš„è¦†ç›–ç‡"""
        from fnmatch import fnmatch
        
        layer_files = []
        total_lines = 0
        covered_lines = 0
        
        files = self.coverage_data.get('files', {})
        
        for file_path in files.keys():
            if fnmatch(file_path, layer_threshold.files_pattern):
                file_data = files[file_path]
                summary = file_data.get('summary', {})
                
                file_total = summary.get('num_statements', 0)
                file_covered = summary.get('covered_lines', 0)
                
                total_lines += file_total
                covered_lines += file_covered
                layer_files.append(file_path)
        
        if total_lines == 0:
            print(f"âš ï¸  {layer_threshold.layer}å±‚æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶")
            return True
        
        layer_coverage = (covered_lines / total_lines) * 100
        
        print(f"ğŸ“Š {layer_threshold.layer}å±‚è¦†ç›–ç‡: {layer_coverage:.2f}% "
              f"(è¦æ±‚: â‰¥{layer_threshold.min_coverage}%)")
        
        if layer_coverage < layer_threshold.min_coverage:
            print(f"âŒ {layer_threshold.layer}å±‚è¦†ç›–ç‡ä¸è¾¾æ ‡")
            print(f"   åŒ…å«æ–‡ä»¶: {len(layer_files)}ä¸ª")
            return False
        
        print(f"âœ… {layer_threshold.layer}å±‚è¦†ç›–ç‡è¾¾æ ‡")
        return True
    
    def check_file_coverage_regression(self, baseline_file: str = None) -> bool:
        """æ£€æŸ¥æ–‡ä»¶çº§è¦†ç›–ç‡å›å½’"""
        if not baseline_file or not Path(baseline_file).exists():
            print("âš ï¸  æ²¡æœ‰åŸºçº¿è¦†ç›–ç‡æ–‡ä»¶ï¼Œè·³è¿‡å›å½’æ£€æŸ¥")
            return True
        
        try:
            with open(baseline_file, 'r') as f:
                baseline_data = json.load(f)
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–åŸºçº¿è¦†ç›–ç‡æ–‡ä»¶: {e}")
            return True
        
        current_files = self.coverage_data.get('files', {})
        baseline_files = baseline_data.get('files', {})
        
        regressions = []
        
        for file_path in current_files.keys():
            if file_path in baseline_files:
                current_coverage = current_files[file_path]['summary']['percent_covered']
                baseline_coverage = baseline_files[file_path]['summary']['percent_covered']
                
                # å…è®¸1%çš„è¦†ç›–ç‡ä¸‹é™
                if current_coverage < baseline_coverage - 1.0:
                    regressions.append({
                        'file': file_path,
                        'current': current_coverage,
                        'baseline': baseline_coverage,
                        'diff': current_coverage - baseline_coverage
                    })
        
        if regressions:
            print(f"âŒ å‘ç° {len(regressions)} ä¸ªæ–‡ä»¶è¦†ç›–ç‡å›å½’:")
            for reg in regressions:
                print(f"   {reg['file']}: {reg['current']:.1f}% â†’ {reg['baseline']:.1f}% "
                      f"({reg['diff']:+.1f}%)")
            return False
        
        print("âœ… æ— è¦†ç›–ç‡å›å½’")
        return True
    
    def generate_coverage_report(self) -> str:
        """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
        overall_coverage = self.get_overall_coverage()
        
        report = [
            "# æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            f"## æ•´ä½“è¦†ç›–ç‡: {overall_coverage:.2f}%",
            ""
        ]
        
        # è¦†ç›–ç‡çŠ¶æ€
        if overall_coverage >= 90:
            status = "ğŸŸ¢ ä¼˜ç§€"
        elif overall_coverage >= 80:
            status = "ğŸŸ¡ è‰¯å¥½"
        elif overall_coverage >= 70:
            status = "ğŸŸ  åŠæ ¼"
        else:
            status = "ğŸ”´ ä¸åŠæ ¼"
        
        report.append(f"çŠ¶æ€: {status}")
        report.append("")
        
        # åˆ†å±‚è¦†ç›–ç‡
        report.append("## åˆ†å±‚è¦†ç›–ç‡")
        for threshold in self.LAYER_THRESHOLDS:
            layer_pass = self.check_layer_coverage(threshold)
            status_icon = "âœ…" if layer_pass else "âŒ"
            report.append(f"- {threshold.layer}: {status_icon}")
        
        report.append("")
        
        # ä½è¦†ç›–ç‡æ–‡ä»¶
        report.append("## ä½è¦†ç›–ç‡æ–‡ä»¶ (<70%)")
        files = self.coverage_data.get('files', {})
        low_coverage_files = []
        
        for file_path, file_data in files.items():
            coverage = file_data['summary']['percent_covered']
            if coverage < 70:
                low_coverage_files.append((file_path, coverage))
        
        low_coverage_files.sort(key=lambda x: x[1])
        
        if low_coverage_files:
            for file_path, coverage in low_coverage_files:
                report.append(f"- {file_path}: {coverage:.1f}%")
        else:
            report.append("æ— ä½è¦†ç›–ç‡æ–‡ä»¶")
        
        return "\n".join(report)
    
    def save_baseline(self, baseline_file: str = "coverage_baseline.json"):
        """ä¿å­˜å½“å‰è¦†ç›–ç‡ä½œä¸ºåŸºçº¿"""
        import shutil
        shutil.copy2(self.coverage_file, baseline_file)
        print(f"âœ… è¦†ç›–ç‡åŸºçº¿å·²ä¿å­˜åˆ° {baseline_file}")
    
    def run_full_check(self, 
                      min_overall: float = 80.0,
                      baseline_file: str = None,
                      save_baseline: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´çš„è¦†ç›–ç‡æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹è¦†ç›–ç‡æ£€æŸ¥...\n")
        
        all_passed = True
        
        # 1. æ•´ä½“è¦†ç›–ç‡æ£€æŸ¥
        overall_coverage = self.get_overall_coverage()
        print(f"ğŸ“Š æ•´ä½“è¦†ç›–ç‡: {overall_coverage:.2f}% (è¦æ±‚: â‰¥{min_overall}%)")
        
        if overall_coverage < min_overall:
            print("âŒ æ•´ä½“è¦†ç›–ç‡ä¸è¾¾æ ‡")
            all_passed = False
        else:
            print("âœ… æ•´ä½“è¦†ç›–ç‡è¾¾æ ‡")
        
        print()
        
        # 2. åˆ†å±‚è¦†ç›–ç‡æ£€æŸ¥
        print("ğŸ” æ£€æŸ¥åˆ†å±‚è¦†ç›–ç‡...")
        for threshold in self.LAYER_THRESHOLDS:
            if not self.check_layer_coverage(threshold):
                all_passed = False
        
        print()
        
        # 3. è¦†ç›–ç‡å›å½’æ£€æŸ¥
        print("ğŸ” æ£€æŸ¥è¦†ç›–ç‡å›å½’...")
        if not self.check_file_coverage_regression(baseline_file):
            all_passed = False
        
        print()
        
        # 4. ä¿å­˜åŸºçº¿ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if save_baseline:
            self.save_baseline()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_coverage_report()
        with open("coverage_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        print("ğŸ“‹ è¦†ç›–ç‡æŠ¥å‘Šå·²ç”Ÿæˆ: coverage_report.md")
        
        return all_passed

def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•è¦†ç›–ç‡ç›‘æ§")
    parser.add_argument("--min-overall", type=float, default=80.0,
                       help="æœ€ä½æ•´ä½“è¦†ç›–ç‡è¦æ±‚")
    parser.add_argument("--baseline", type=str,
                       help="åŸºçº¿è¦†ç›–ç‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--save-baseline", action="store_true",
                       help="ä¿å­˜å½“å‰è¦†ç›–ç‡ä½œä¸ºåŸºçº¿")
    parser.add_argument("--coverage-file", type=str, default="coverage.json",
                       help="è¦†ç›–ç‡æ•°æ®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    monitor = CoverageMonitor(args.coverage_file)
    
    success = monitor.run_full_check(
        min_overall=args.min_overall,
        baseline_file=args.baseline,
        save_baseline=args.save_baseline
    )
    
    if not success:
        print("\nâŒ è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥")
        sys.exit(1)
    
    print("\nâœ… è¦†ç›–ç‡æ£€æŸ¥é€šè¿‡")

if __name__ == "__main__":
    main()
```

#### 1.3.2 è¦†ç›–ç‡å·®å¼‚åˆ†æè„šæœ¬
```python
# scripts/coverage_diff.py
import json
import sys
import argparse
from typing import Dict, List, NamedTuple
from pathlib import Path

class FileCoverageDiff(NamedTuple):
    """æ–‡ä»¶è¦†ç›–ç‡å·®å¼‚"""
    file_path: str
    before: float
    after: float
    diff: float
    status: str  # "improved", "declined", "unchanged"

class CoverageDiffAnalyzer:
    """è¦†ç›–ç‡å·®å¼‚åˆ†æå™¨"""
    
    def __init__(self, before_file: str, after_file: str):
        self.before_data = self._load_coverage_data(before_file)
        self.after_data = self._load_coverage_data(after_file)
    
    def _load_coverage_data(self, file_path: str) -> Dict:
        """åŠ è½½è¦†ç›–ç‡æ•°æ®"""
        try:
            with open(file_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯: {file_path}")
            sys.exit(1)
    
    def analyze_overall_diff(self) -> Dict:
        """åˆ†ææ•´ä½“è¦†ç›–ç‡å·®å¼‚"""
        before_total = self.before_data.get('totals', {})
        after_total = self.after_data.get('totals', {})
        
        before_coverage = before_total.get('percent_covered', 0.0)
        after_coverage = after_total.get('percent_covered', 0.0)
        
        return {
            'before': before_coverage,
            'after': after_coverage,
            'diff': after_coverage - before_coverage,
            'before_lines': before_total.get('num_statements', 0),
            'after_lines': after_total.get('num_statements', 0),
            'before_covered': before_total.get('covered_lines', 0),
            'after_covered': after_total.get('covered_lines', 0)
        }
    
    def analyze_file_diffs(self, min_diff: float = 1.0) -> List[FileCoverageDiff]:
        """åˆ†ææ–‡ä»¶çº§è¦†ç›–ç‡å·®å¼‚"""
        before_files = self.before_data.get('files', {})
        after_files = self.after_data.get('files', {})
        
        # è·å–æ‰€æœ‰æ–‡ä»¶
        all_files = set(before_files.keys()) | set(after_files.keys())
        
        diffs = []
        
        for file_path in all_files:
            before_coverage = 0.0
            after_coverage = 0.0
            
            if file_path in before_files:
                before_coverage = before_files[file_path]['summary']['percent_covered']
            
            if file_path in after_files:
                after_coverage = after_files[file_path]['summary']['percent_covered']
            
            diff = after_coverage - before_coverage
            
            # åªå…³æ³¨æ˜¾è‘—å˜åŒ–
            if abs(diff) >= min_diff:
                if diff > 0:
                    status = "improved"
                elif diff < 0:
                    status = "declined"
                else:
                    status = "unchanged"
                
                diffs.append(FileCoverageDiff(
                    file_path=file_path,
                    before=before_coverage,
                    after=after_coverage,
                    diff=diff,
                    status=status
                ))
        
        return sorted(diffs, key=lambda x: abs(x.diff), reverse=True)
    
    def generate_diff_report(self, min_diff: float = 1.0) -> str:
        """ç”Ÿæˆå·®å¼‚æŠ¥å‘Š"""
        overall_diff = self.analyze_overall_diff()
        file_diffs = self.analyze_file_diffs(min_diff)
        
        report = [
            "# è¦†ç›–ç‡å·®å¼‚æŠ¥å‘Š",
            "",
            "## æ•´ä½“è¦†ç›–ç‡å˜åŒ–",
            f"- å˜æ›´å‰: {overall_diff['before']:.2f}%",
            f"- å˜æ›´å: {overall_diff['after']:.2f}%",
            f"- å·®å¼‚: {overall_diff['diff']:+.2f}%",
            "",
            f"## ä»£ç è¡Œæ•°å˜åŒ–",
            f"- æ€»è¡Œæ•°: {overall_diff['before_lines']} â†’ {overall_diff['after_lines']} "
            f"({overall_diff['after_lines'] - overall_diff['before_lines']:+d})",
            f"- è¦†ç›–è¡Œæ•°: {overall_diff['before_covered']} â†’ {overall_diff['after_covered']} "
            f"({overall_diff['after_covered'] - overall_diff['before_covered']:+d})",
            ""
        ]
        
        if file_diffs:
            report.append(f"## æ–‡ä»¶çº§è¦†ç›–ç‡å˜åŒ– (å·®å¼‚ â‰¥{min_diff}%)")
            report.append("")
            
            # è¦†ç›–ç‡æå‡çš„æ–‡ä»¶
            improved_files = [f for f in file_diffs if f.status == "improved"]
            if improved_files:
                report.append("### ğŸ“ˆ è¦†ç›–ç‡æå‡")
                for file_diff in improved_files:
                    report.append(f"- {file_diff.file_path}: "
                                f"{file_diff.before:.1f}% â†’ {file_diff.after:.1f}% "
                                f"(+{file_diff.diff:.1f}%)")
                report.append("")
            
            # è¦†ç›–ç‡ä¸‹é™çš„æ–‡ä»¶
            declined_files = [f for f in file_diffs if f.status == "declined"]
            if declined_files:
                report.append("### ğŸ“‰ è¦†ç›–ç‡ä¸‹é™")
                for file_diff in declined_files:
                    report.append(f"- {file_diff.file_path}: "
                                f"{file_diff.before:.1f}% â†’ {file_diff.after:.1f}% "
                                f"({file_diff.diff:.1f}%)")
                report.append("")
        else:
            report.append(f"## æ— æ˜¾è‘—æ–‡ä»¶çº§è¦†ç›–ç‡å˜åŒ– (å·®å¼‚ <{min_diff}%)")
        
        return "\n".join(report)

def main():
    parser = argparse.ArgumentParser(description="è¦†ç›–ç‡å·®å¼‚åˆ†æ")
    parser.add_argument("before", help="å˜æ›´å‰çš„è¦†ç›–ç‡æ–‡ä»¶")
    parser.add_argument("after", help="å˜æ›´åçš„è¦†ç›–ç‡æ–‡ä»¶")
    parser.add_argument("--min-diff", type=float, default=1.0,
                       help="æœ€å°å·®å¼‚é˜ˆå€¼ (é»˜è®¤: 1.0%)")
    parser.add_argument("--output", type=str, default="coverage_diff.md",
                       help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶")
    
    args = parser.parse_args()
    
    analyzer = CoverageDiffAnalyzer(args.before, args.after)
    report = analyzer.generate_diff_report(args.min_diff)
    
    # è¾“å‡ºåˆ°æ–‡ä»¶
    with open(args.output, "w", encoding="utf-8") as f:
        f.write(report)
    
    # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    print(report)
    print(f"\nğŸ“‹ å·®å¼‚æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")

if __name__ == "__main__":
    main()
```

## 2. è´¨é‡åº¦é‡ä»ªè¡¨æ¿

### 2.1 è¦†ç›–ç‡å¯è§†åŒ–

#### 2.1.1 è¦†ç›–ç‡å¾½ç« ç”Ÿæˆ
```python
# scripts/generate_badges.py
import json
import requests
from pathlib import Path

class BadgeGenerator:
    """å¾½ç« ç”Ÿæˆå™¨"""
    
    SHIELDS_API = "https://img.shields.io/badge"
    
    def __init__(self, coverage_file: str = "coverage.json"):
        self.coverage_file = coverage_file
        self.coverage_data = self._load_coverage_data()
    
    def _load_coverage_data(self):
        """åŠ è½½è¦†ç›–ç‡æ•°æ®"""
        with open(self.coverage_file, 'r') as f:
            return json.load(f)
    
    def get_coverage_color(self, coverage: float) -> str:
        """æ ¹æ®è¦†ç›–ç‡è·å–é¢œè‰²"""
        if coverage >= 90:
            return "brightgreen"
        elif coverage >= 80:
            return "green"
        elif coverage >= 70:
            return "yellow"
        elif coverage >= 60:
            return "orange"
        else:
            return "red"
    
    def generate_coverage_badge(self) -> str:
        """ç”Ÿæˆè¦†ç›–ç‡å¾½ç« URL"""
        overall_coverage = self.coverage_data['totals']['percent_covered']
        color = self.get_coverage_color(overall_coverage)
        
        return f"{self.SHIELDS_API}/coverage-{overall_coverage:.1f}%25-{color}"
    
    def generate_layer_badges(self) -> dict:
        """ç”Ÿæˆåˆ†å±‚è¦†ç›–ç‡å¾½ç« """
        from coverage_monitor import CoverageMonitor
        
        monitor = CoverageMonitor(self.coverage_file)
        badges = {}
        
        for threshold in monitor.LAYER_THRESHOLDS:
            # è¿™é‡Œéœ€è¦è®¡ç®—æ¯å±‚çš„å®é™…è¦†ç›–ç‡
            # ç®€åŒ–å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦å®Œå–„
            layer_coverage = 85.0  # ç¤ºä¾‹å€¼
            color = self.get_coverage_color(layer_coverage)
            
            badges[threshold.layer] = (
                f"{self.SHIELDS_API}/{threshold.layer}-{layer_coverage:.1f}%25-{color}"
            )
        
        return badges
    
    def update_readme_badges(self, readme_file: str = "README.md"):
        """æ›´æ–°READMEä¸­çš„å¾½ç« """
        if not Path(readme_file).exists():
            return
        
        with open(readme_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        coverage_badge = self.generate_coverage_badge()
        
        # æ›´æ–°è¦†ç›–ç‡å¾½ç« 
        import re
        pattern = r'!\[Coverage\]\(.*?\)'
        replacement = f'![Coverage]({coverage_badge})'
        
        if re.search(pattern, content):
            content = re.sub(pattern, replacement, content)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¾½ç« ï¼Œæ·»åŠ åˆ°æ–‡ä»¶å¼€å¤´
            badge_section = f"![Coverage]({coverage_badge})\n\n"
            content = badge_section + content
        
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… READMEå¾½ç« å·²æ›´æ–°")

def main():
    generator = BadgeGenerator()
    
    # ç”Ÿæˆå¹¶æ‰“å°å¾½ç« URL
    coverage_badge = generator.generate_coverage_badge()
    print(f"è¦†ç›–ç‡å¾½ç« : {coverage_badge}")
    
    layer_badges = generator.generate_layer_badges()
    for layer, badge_url in layer_badges.items():
        print(f"{layer}å±‚å¾½ç« : {badge_url}")
    
    # æ›´æ–°README
    generator.update_readme_badges()

if __name__ == "__main__":
    main()
```

#### 2.1.2 HTMLè¦†ç›–ç‡æŠ¥å‘Šå¢å¼º
```python
# scripts/enhance_html_report.py
import json
import os
from pathlib import Path
from jinja2 import Template

class HtmlReportEnhancer:
    """HTMLè¦†ç›–ç‡æŠ¥å‘Šå¢å¼ºå™¨"""
    
    def __init__(self, coverage_file: str = "coverage.json", html_dir: str = "htmlcov"):
        self.coverage_file = coverage_file
        self.html_dir = Path(html_dir)
        self.coverage_data = self._load_coverage_data()
    
    def _load_coverage_data(self):
        """åŠ è½½è¦†ç›–ç‡æ•°æ®"""
        with open(self.coverage_file, 'r') as f:
            return json.load(f)
    
    def generate_dashboard(self):
        """ç”Ÿæˆè¦†ç›–ç‡ä»ªè¡¨æ¿"""
        template_str = '''
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>LingShu è¦†ç›–ç‡ä»ªè¡¨æ¿</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .metric-card { 
            display: inline-block; margin: 10px; padding: 20px; 
            border: 1px solid #ddd; border-radius: 8px; text-align: center;
            min-width: 150px;
        }
        .metric-value { font-size: 2em; font-weight: bold; }
        .metric-label { color: #666; margin-top: 5px; }
        .chart-container { width: 400px; height: 400px; margin: 20px; display: inline-block; }
        .status-good { color: #28a745; }
        .status-warning { color: #ffc107; }
        .status-danger { color: #dc3545; }
    </style>
</head>
<body>
    <h1>LingShu æµ‹è¯•è¦†ç›–ç‡ä»ªè¡¨æ¿</h1>
    
    <div class="metrics">
        <div class="metric-card">
            <div class="metric-value status-{{ overall_status }}">{{ overall_coverage }}%</div>
            <div class="metric-label">æ•´ä½“è¦†ç›–ç‡</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ total_files }}</div>
            <div class="metric-label">æ€»æ–‡ä»¶æ•°</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ total_lines }}</div>
            <div class="metric-label">æ€»è¡Œæ•°</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ covered_lines }}</div>
            <div class="metric-label">è¦†ç›–è¡Œæ•°</div>
        </div>
    </div>
    
    <div class="charts">
        <div class="chart-container">
            <canvas id="layerChart"></canvas>
        </div>
        
        <div class="chart-container">
            <canvas id="trendChart"></canvas>
        </div>
    </div>
    
    <h2>åˆ†å±‚è¦†ç›–ç‡</h2>
    <table border="1" style="border-collapse: collapse; width: 100%;">
        <tr>
            <th>å±‚çº§</th>
            <th>è¦†ç›–ç‡</th>
            <th>çŠ¶æ€</th>
            <th>æ–‡ä»¶æ•°</th>
        </tr>
        {% for layer in layers %}
        <tr>
            <td>{{ layer.name }}</td>
            <td>{{ layer.coverage }}%</td>
            <td class="status-{{ layer.status }}">{{ layer.status_text }}</td>
            <td>{{ layer.file_count }}</td>
        </tr>
        {% endfor %}
    </table>
    
    <script>
        // åˆ†å±‚è¦†ç›–ç‡é¥¼å›¾
        const layerCtx = document.getElementById('layerChart').getContext('2d');
        new Chart(layerCtx, {
            type: 'doughnut',
            data: {
                labels: {{ layer_labels | tojson }},
                datasets: [{
                    data: {{ layer_data | tojson }},
                    backgroundColor: ['#28a745', '#17a2b8', '#ffc107', '#fd7e14']
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'åˆ†å±‚è¦†ç›–ç‡åˆ†å¸ƒ'
                    }
                }
            }
        });
        
        // è¦†ç›–ç‡è¶‹åŠ¿å›¾ï¼ˆç¤ºä¾‹æ•°æ®ï¼‰
        const trendCtx = document.getElementById('trendChart').getContext('2d');
        new Chart(trendCtx, {
            type: 'line',
            data: {
                labels: ['Week 1', 'Week 2', 'Week 3', 'Week 4'],
                datasets: [{
                    label: 'æ•´ä½“è¦†ç›–ç‡',
                    data: [75, 78, 82, {{ overall_coverage }}],
                    borderColor: '#007bff',
                    fill: false
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'è¦†ç›–ç‡è¶‹åŠ¿'
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 100
                    }
                }
            }
        });
    </script>
</body>
</html>
        '''
        
        # å‡†å¤‡æ¨¡æ¿æ•°æ®
        totals = self.coverage_data['totals']
        overall_coverage = totals['percent_covered']
        
        # ç¡®å®šçŠ¶æ€
        if overall_coverage >= 90:
            overall_status = "good"
        elif overall_coverage >= 80:
            overall_status = "warning"
        else:
            overall_status = "danger"
        
        # æ¨¡æ‹Ÿåˆ†å±‚æ•°æ®ï¼ˆå®é™…é¡¹ç›®ä¸­éœ€è¦è®¡ç®—ï¼‰
        layers = [
            {
                'name': 'Domain',
                'coverage': 95.0,
                'status': 'good',
                'status_text': 'ä¼˜ç§€',
                'file_count': 5
            },
            {
                'name': 'Application',
                'coverage': 88.0,
                'status': 'warning',
                'status_text': 'è‰¯å¥½',
                'file_count': 3
            },
            {
                'name': 'API',
                'coverage': 82.0,
                'status': 'warning',
                'status_text': 'è‰¯å¥½',
                'file_count': 4
            },
            {
                'name': 'Infrastructure',
                'coverage': 75.0,
                'status': 'warning',
                'status_text': 'åŠæ ¼',
                'file_count': 6
            }
        ]
        
        template_data = {
            'overall_coverage': f"{overall_coverage:.1f}",
            'overall_status': overall_status,
            'total_files': len(self.coverage_data['files']),
            'total_lines': totals['num_statements'],
            'covered_lines': totals['covered_lines'],
            'layers': layers,
            'layer_labels': [layer['name'] for layer in layers],
            'layer_data': [layer['coverage'] for layer in layers]
        }
        
        template = Template(template_str)
        html_content = template.render(**template_data)
        
        # ä¿å­˜ä»ªè¡¨æ¿
        dashboard_file = self.html_dir / "dashboard.html"
        with open(dashboard_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… è¦†ç›–ç‡ä»ªè¡¨æ¿å·²ç”Ÿæˆ: {dashboard_file}")

def main():
    enhancer = HtmlReportEnhancer()
    enhancer.generate_dashboard()

if __name__ == "__main__":
    main()
```

## 3. CI/CDé›†æˆ

### 3.1 GitHub Actionsè¦†ç›–ç‡å·¥ä½œæµ

#### 3.1.1 è¦†ç›–ç‡æ”¶é›†å’ŒæŠ¥å‘Š
```yaml
# .github/workflows/coverage.yml
name: Coverage Analysis

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  coverage:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # è·å–å®Œæ•´å†å²ï¼Œç”¨äºè¶‹åŠ¿åˆ†æ
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run tests with coverage
        run: |
          pytest --cov=app --cov-report=xml --cov-report=json --cov-report=html
        env:
          DATABASE_URL: sqlite:///test.db
      
      - name: Download baseline coverage
        if: github.event_name == 'pull_request'
        run: |
          # å°è¯•ä¸‹è½½mainåˆ†æ”¯çš„è¦†ç›–ç‡ä½œä¸ºåŸºçº¿
          curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
               -H "Accept: application/vnd.github.v3.raw" \
               -o coverage_baseline.json \
               "https://api.github.com/repos/${{ github.repository }}/contents/coverage.json?ref=main" \
               || echo "No baseline coverage found"
      
      - name: Run coverage analysis
        run: |
          python scripts/coverage_monitor.py --min-overall 80 \
            $([ -f coverage_baseline.json ] && echo "--baseline coverage_baseline.json")
      
      - name: Generate coverage diff (PR only)
        if: github.event_name == 'pull_request' && hashFiles('coverage_baseline.json') != ''
        run: |
          python scripts/coverage_diff.py coverage_baseline.json coverage.json \
            --output coverage_diff.md
      
      - name: Update coverage badges
        if: github.ref == 'refs/heads/main'
        run: |
          python scripts/generate_badges.py
      
      - name: Generate enhanced HTML report
        run: |
          python scripts/enhance_html_report.py
      
      - name: Upload coverage reports
        uses: actions/upload-artifact@v3
        with:
          name: coverage-reports
          path: |
            coverage.xml
            coverage.json
            htmlcov/
            coverage_report.md
            coverage_diff.md
      
      - name: Upload to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
      
      - name: Comment PR with coverage diff
        if: github.event_name == 'pull_request' && hashFiles('coverage_diff.md') != ''
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const diffReport = fs.readFileSync('coverage_diff.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ğŸ“Š è¦†ç›–ç‡å˜åŒ–æŠ¥å‘Š\n\n${diffReport}`
            });
      
      - name: Fail if coverage drops
        if: github.event_name == 'pull_request'
        run: |
          # æ£€æŸ¥è¦†ç›–ç‡æ˜¯å¦ä¸‹é™è¶…è¿‡é˜ˆå€¼
          python -c "
          import json, sys
          
          try:
              with open('coverage.json') as f:
                  current = json.load(f)['totals']['percent_covered']
              
              try:
                  with open('coverage_baseline.json') as f:
                      baseline = json.load(f)['totals']['percent_covered']
                  
                  if current < baseline - 2.0:  # å…è®¸2%çš„ä¸‹é™
                      print(f'âŒ è¦†ç›–ç‡ä¸‹é™è¿‡å¤š: {baseline:.1f}% â†’ {current:.1f}%')
                      sys.exit(1)
              except FileNotFoundError:
                  print('âš ï¸ æ²¡æœ‰åŸºçº¿æ•°æ®ï¼Œè·³è¿‡å›å½’æ£€æŸ¥')
              
              print(f'âœ… è¦†ç›–ç‡æ£€æŸ¥é€šè¿‡: {current:.1f}%')
          except Exception as e:
              print(f'âš ï¸ è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: {e}')
          "
```

### 3.2 è´¨é‡åº¦é‡é›†æˆ

#### 3.2.1 SonarQubeé›†æˆ
```yaml
# .github/workflows/sonarqube.yml
name: SonarQube Analysis

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  sonarqube:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run tests with coverage
        run: |
          pytest --cov=app --cov-report=xml --cov-report=json
        env:
          DATABASE_URL: sqlite:///test.db
      
      - name: Run SonarQube Scan
        uses: sonarqube-quality-gate-action@master
        with:
          scanMetadataReportFile: target/sonar/report-task.txt
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
```

#### 3.2.2 ä»£ç è´¨é‡é…ç½®
```properties
# sonar-project.properties
sonar.projectKey=lingshu-backend
sonar.projectName=LingShu Backend
sonar.projectVersion=1.0.0

# Source code
sonar.sources=app
sonar.tests=tests
sonar.python.version=3.12

# Coverage reports
sonar.python.coverage.reportPaths=coverage.xml
sonar.python.xunit.reportPath=test-results.xml

# Exclusions
sonar.exclusions=**/migrations/**,**/__pycache__/**,**/venv/**

# Quality Gate
sonar.qualitygate.wait=true

# Code coverage
sonar.coverage.minimum=80.0

# Duplication
sonar.cpd.python.minimumtokens=50

# Technical debt
sonar.technicalDebt.hoursInDay=8
sonar.technicalDebt.ratingGrid=0.1,0.2,0.5,1.0
```

## 4. è¦†ç›–ç‡ä¼˜åŒ–ç­–ç•¥

### 4.1 ä½è¦†ç›–ç‡è¯†åˆ«å’Œæ”¹è¿›

#### 4.1.1 ä½è¦†ç›–ç‡æ–‡ä»¶åˆ†æè„šæœ¬
```python
# scripts/analyze_low_coverage.py
import json
import ast
import sys
from pathlib import Path
from typing import List, Dict, NamedTuple

class UncoveredCode(NamedTuple):
    """æœªè¦†ç›–ä»£ç """
    file_path: str
    line_number: int
    line_content: str
    function_name: str
    complexity: int

class LowCoverageAnalyzer:
    """ä½è¦†ç›–ç‡åˆ†æå™¨"""
    
    def __init__(self, coverage_file: str = "coverage.json"):
        self.coverage_data = self._load_coverage_data(coverage_file)
    
    def _load_coverage_data(self, file_path: str) -> Dict:
        """åŠ è½½è¦†ç›–ç‡æ•°æ®"""
        with open(file_path, 'r') as f:
            return json.load(f)
    
    def get_low_coverage_files(self, threshold: float = 70.0) -> List[Dict]:
        """è·å–ä½è¦†ç›–ç‡æ–‡ä»¶"""
        files = self.coverage_data.get('files', {})
        low_coverage_files = []
        
        for file_path, file_data in files.items():
            coverage = file_data['summary']['percent_covered']
            if coverage < threshold:
                low_coverage_files.append({
                    'file_path': file_path,
                    'coverage': coverage,
                    'missing_lines': file_data.get('missing_lines', []),
                    'total_lines': file_data['summary']['num_statements'],
                    'covered_lines': file_data['summary']['covered_lines']
                })
        
        return sorted(low_coverage_files, key=lambda x: x['coverage'])
    
    def analyze_uncovered_code(self, file_path: str) -> List[UncoveredCode]:
        """åˆ†ææœªè¦†ç›–çš„ä»£ç """
        if not Path(file_path).exists():
            return []
        
        file_data = self.coverage_data['files'].get(file_path, {})
        missing_lines = file_data.get('missing_lines', [])
        
        if not missing_lines:
            return []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            tree = ast.parse(''.join(lines))
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è§£ææ–‡ä»¶ {file_path}: {e}")
            return []
        
        uncovered_code = []
        
        for line_num in missing_lines:
            if 1 <= line_num <= len(lines):
                line_content = lines[line_num - 1].strip()
                
                # æŸ¥æ‰¾åŒ…å«æ­¤è¡Œçš„å‡½æ•°
                function_name = self._find_function_for_line(tree, line_num)
                
                # è®¡ç®—å‡½æ•°å¤æ‚åº¦
                complexity = self._calculate_function_complexity(tree, function_name)
                
                uncovered_code.append(UncoveredCode(
                    file_path=file_path,
                    line_number=line_num,
                    line_content=line_content,
                    function_name=function_name,
                    complexity=complexity
                ))
        
        return uncovered_code
    
    def _find_function_for_line(self, tree: ast.AST, line_num: int) -> str:
        """æŸ¥æ‰¾åŒ…å«æŒ‡å®šè¡Œçš„å‡½æ•°"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                if hasattr(node, 'lineno') and hasattr(node, 'end_lineno'):
                    if node.lineno <= line_num <= (node.end_lineno or line_num):
                        return node.name
        return "æœªçŸ¥å‡½æ•°"
    
    def _calculate_function_complexity(self, tree: ast.AST, function_name: str) -> int:
        """è®¡ç®—å‡½æ•°å¤æ‚åº¦"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                if node.name == function_name:
                    complexity = 1  # åŸºç¡€å¤æ‚åº¦
                    
                    for child in ast.walk(node):
                        if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                            complexity += 1
                        elif isinstance(child, ast.ExceptHandler):
                            complexity += 1
                    
                    return complexity
        return 1
    
    def generate_improvement_suggestions(self, threshold: float = 70.0) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        low_coverage_files = self.get_low_coverage_files(threshold)
        
        if not low_coverage_files:
            return "ğŸ‰ æ‰€æœ‰æ–‡ä»¶çš„è¦†ç›–ç‡éƒ½è¾¾æ ‡ï¼"
        
        suggestions = [
            f"# è¦†ç›–ç‡æ”¹è¿›å»ºè®®",
            f"",
            f"å‘ç° {len(low_coverage_files)} ä¸ªæ–‡ä»¶çš„è¦†ç›–ç‡ä½äº {threshold}%",
            f""
        ]
        
        for file_info in low_coverage_files:
            suggestions.append(f"## {file_info['file_path']}")
            suggestions.append(f"- å½“å‰è¦†ç›–ç‡: {file_info['coverage']:.1f}%")
            suggestions.append(f"- æœªè¦†ç›–è¡Œæ•°: {len(file_info['missing_lines'])}")
            suggestions.append(f"- ä¼˜å…ˆçº§: {'é«˜' if file_info['coverage'] < 50 else 'ä¸­' if file_info['coverage'] < 60 else 'ä½'}")
            
            # åˆ†ææœªè¦†ç›–ä»£ç 
            uncovered_code = self.analyze_uncovered_code(file_info['file_path'])
            
            if uncovered_code:
                suggestions.append("- ä¸»è¦æœªè¦†ç›–ä»£ç :")
                
                # æŒ‰å¤æ‚åº¦æ’åºï¼Œä¼˜å…ˆæ˜¾ç¤ºå¤æ‚åº¦é«˜çš„
                sorted_uncovered = sorted(uncovered_code, key=lambda x: x.complexity, reverse=True)
                
                for code in sorted_uncovered[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    suggestions.append(f"  - è¡Œ {code.line_number} ({code.function_name}): "
                                     f"`{code.line_content}` (å¤æ‚åº¦: {code.complexity})")
            
            suggestions.append("")
            
            # æä¾›å…·ä½“å»ºè®®
            if file_info['coverage'] < 50:
                suggestions.append("### ğŸ”´ ç´§æ€¥æ”¹è¿›å»ºè®®:")
                suggestions.append("- è¿™ä¸ªæ–‡ä»¶çš„è¦†ç›–ç‡æä½ï¼Œå»ºè®®ç«‹å³æ·»åŠ å•å…ƒæµ‹è¯•")
                suggestions.append("- ä¼˜å…ˆæµ‹è¯•æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å’Œå¤æ‚åº¦é«˜çš„å‡½æ•°")
            elif file_info['coverage'] < 70:
                suggestions.append("### ğŸŸ¡ æ”¹è¿›å»ºè®®:")
                suggestions.append("- æ·»åŠ æµ‹è¯•è¦†ç›–å¼‚å¸¸å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶")
                suggestions.append("- è€ƒè™‘æ·»åŠ é›†æˆæµ‹è¯•éªŒè¯ç»„ä»¶äº¤äº’")
            
            suggestions.append("")
        
        return "\n".join(suggestions)

def main():
    analyzer = LowCoverageAnalyzer()
    
    # ç”Ÿæˆæ”¹è¿›å»ºè®®
    suggestions = analyzer.generate_improvement_suggestions()
    print(suggestions)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("coverage_improvement.md", "w", encoding="utf-8") as f:
        f.write(suggestions)
    
    print(f"\nğŸ“‹ æ”¹è¿›å»ºè®®å·²ä¿å­˜åˆ°: coverage_improvement.md")

if __name__ == "__main__":
    main()
```

### 4.2 æµ‹è¯•ç”ŸæˆåŠ©æ‰‹

#### 4.2.1 è‡ªåŠ¨æµ‹è¯•æ¨¡æ¿ç”Ÿæˆ
```python
# scripts/test_generator.py
import ast
import sys
from pathlib import Path
from typing import List, Dict, Optional

class TestGenerator:
    """æµ‹è¯•ç”Ÿæˆå™¨"""
    
    def __init__(self, source_file: str):
        self.source_file = Path(source_file)
        self.source_code = self._read_source_code()
        self.ast_tree = self._parse_source_code()
    
    def _read_source_code(self) -> str:
        """è¯»å–æºä»£ç """
        try:
            with open(self.source_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {self.source_file}: {e}")
            sys.exit(1)
    
    def _parse_source_code(self) -> ast.AST:
        """è§£ææºä»£ç """
        try:
            return ast.parse(self.source_code)
        except SyntaxError as e:
            print(f"âŒ è¯­æ³•é”™è¯¯ {self.source_file}: {e}")
            sys.exit(1)
    
    def extract_classes_and_functions(self) -> Dict:
        """æå–ç±»å’Œå‡½æ•°ä¿¡æ¯"""
        classes = []
        functions = []
        
        for node in ast.walk(self.ast_tree):
            if isinstance(node, ast.ClassDef):
                class_info = {
                    'name': node.name,
                    'methods': [],
                    'docstring': ast.get_docstring(node)
                }
                
                for item in node.body:
                    if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        method_info = self._extract_function_info(item)
                        class_info['methods'].append(method_info)
                
                classes.append(class_info)
            
            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                # åªæå–æ¨¡å—çº§å‡½æ•°
                if isinstance(node, ast.FunctionDef) and node.col_offset == 0:
                    function_info = self._extract_function_info(node)
                    functions.append(function_info)
        
        return {'classes': classes, 'functions': functions}
    
    def _extract_function_info(self, node) -> Dict:
        """æå–å‡½æ•°ä¿¡æ¯"""
        return {
            'name': node.name,
            'args': [arg.arg for arg in node.args.args],
            'returns': self._get_return_type_annotation(node),
            'docstring': ast.get_docstring(node),
            'is_async': isinstance(node, ast.AsyncFunctionDef),
            'decorators': [self._get_decorator_name(d) for d in node.decorator_list]
        }
    
    def _get_return_type_annotation(self, node) -> Optional[str]:
        """è·å–è¿”å›ç±»å‹æ³¨è§£"""
        if node.returns:
            return ast.unparse(node.returns)
        return None
    
    def _get_decorator_name(self, decorator) -> str:
        """è·å–è£…é¥°å™¨åç§°"""
        if isinstance(decorator, ast.Name):
            return decorator.id
        elif isinstance(decorator, ast.Attribute):
            return ast.unparse(decorator)
        else:
            return ast.unparse(decorator)
    
    def generate_test_template(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æ¨¡æ¿"""
        code_info = self.extract_classes_and_functions()
        
        # ç¡®å®šå¯¼å…¥è·¯å¾„
        relative_path = self.source_file.relative_to(Path.cwd())
        import_path = str(relative_path).replace('/', '.').replace('.py', '')
        
        template_lines = [
            f'"""Tests for {relative_path}"""',
            '',
            'import pytest',
            'from unittest.mock import Mock, patch, AsyncMock',
            '',
            f'from {import_path} import (',
        ]
        
        # æ·»åŠ å¯¼å…¥çš„ç±»å’Œå‡½æ•°
        imports = []
        for cls in code_info['classes']:
            imports.append(f'    {cls["name"]},')
        for func in code_info['functions']:
            imports.append(f'    {func["name"]},')
        
        if imports:
            template_lines.extend(imports)
            template_lines[-1] = template_lines[-1].rstrip(',')  # ç§»é™¤æœ€åçš„é€—å·
        
        template_lines.extend([
            ')',
            '',
            ''
        ])
        
        # ä¸ºæ¯ä¸ªç±»ç”Ÿæˆæµ‹è¯•ç±»
        for cls in code_info['classes']:
            template_lines.extend(self._generate_class_tests(cls))
        
        # ä¸ºæ¯ä¸ªå‡½æ•°ç”Ÿæˆæµ‹è¯•å‡½æ•°
        for func in code_info['functions']:
            template_lines.extend(self._generate_function_tests(func))
        
        return '\n'.join(template_lines)
    
    def _generate_class_tests(self, class_info: Dict) -> List[str]:
        """ç”Ÿæˆç±»çš„æµ‹è¯•ä»£ç """
        lines = [
            f'class Test{class_info["name"]}:',
            f'    """Test class for {class_info["name"]}"""',
            '',
            '    @pytest.fixture',
            f'    def {class_info["name"].lower()}_instance(self):',
            f'        """Create a {class_info["name"]} instance for testing"""',
            f'        return {class_info["name"]}()',
            '',
        ]
        
        # ä¸ºæ¯ä¸ªæ–¹æ³•ç”Ÿæˆæµ‹è¯•
        for method in class_info['methods']:
            if method['name'].startswith('_') and not method['name'].startswith('__'):
                continue  # è·³è¿‡ç§æœ‰æ–¹æ³•
            
            lines.extend(self._generate_method_tests(method, class_info['name']))
        
        lines.append('')
        return lines
    
    def _generate_method_tests(self, method_info: Dict, class_name: str) -> List[str]:
        """ç”Ÿæˆæ–¹æ³•çš„æµ‹è¯•ä»£ç """
        method_name = method_info['name']
        is_async = method_info['is_async']
        
        lines = []
        
        # æˆåŠŸè·¯å¾„æµ‹è¯•
        test_name = f'test_{method_name}_success'
        if is_async:
            lines.extend([
                '    @pytest.mark.asyncio',
                f'    async def {test_name}(self, {class_name.lower()}_instance):',
                f'        """Test {method_name} success case"""',
                '        # Arrange',
                '        # TODO: Set up test data',
                '',
                '        # Act',
                f'        result = await {class_name.lower()}_instance.{method_name}()',
                '',
                '        # Assert',
                '        # TODO: Add assertions',
                '        assert result is not None',
                '',
            ])
        else:
            lines.extend([
                f'    def {test_name}(self, {class_name.lower()}_instance):',
                f'        """Test {method_name} success case"""',
                '        # Arrange',
                '        # TODO: Set up test data',
                '',
                '        # Act',
                f'        result = {class_name.lower()}_instance.{method_name}()',
                '',
                '        # Assert',
                '        # TODO: Add assertions',
                '        assert result is not None',
                '',
            ])
        
        # å¦‚æœæ–¹æ³•æœ‰å‚æ•°ï¼Œç”Ÿæˆå‚æ•°åŒ–æµ‹è¯•ç¤ºä¾‹
        if method_info['args'] and len(method_info['args']) > 1:  # æ’é™¤self
            lines.extend([
                f'    @pytest.mark.parametrize("input_data,expected", [',
                '        # TODO: Add test cases',
                '        (None, None),',
                '    ])',
                f'    def test_{method_name}_parametrized(self, {class_name.lower()}_instance, input_data, expected):',
                f'        """Test {method_name} with different inputs"""',
                '        # TODO: Implement parametrized test',
                '        pass',
                '',
            ])
        
        # é”™è¯¯æƒ…å†µæµ‹è¯•
        lines.extend([
            f'    def test_{method_name}_error_case(self, {class_name.lower()}_instance):',
            f'        """Test {method_name} error handling"""',
            '        # TODO: Test error scenarios',
            '        with pytest.raises(Exception):',
            f'            {class_name.lower()}_instance.{method_name}(invalid_input)',
            '',
        ])
        
        return lines
    
    def _generate_function_tests(self, func_info: Dict) -> List[str]:
        """ç”Ÿæˆå‡½æ•°çš„æµ‹è¯•ä»£ç """
        func_name = func_info['name']
        is_async = func_info['is_async']
        
        lines = []
        
        # æˆåŠŸè·¯å¾„æµ‹è¯•
        if is_async:
            lines.extend([
                '@pytest.mark.asyncio',
                f'async def test_{func_name}_success():',
                f'    """Test {func_name} success case"""',
                '    # Arrange',
                '    # TODO: Set up test data',
                '',
                '    # Act',
                f'    result = await {func_name}()',
                '',
                '    # Assert',
                '    # TODO: Add assertions',
                '    assert result is not None',
                '',
            ])
        else:
            lines.extend([
                f'def test_{func_name}_success():',
                f'    """Test {func_name} success case"""',
                '    # Arrange',
                '    # TODO: Set up test data',
                '',
                '    # Act',
                f'    result = {func_name}()',
                '',
                '    # Assert',
                '    # TODO: Add assertions',
                '    assert result is not None',
                '',
            ])
        
        # å‚æ•°åŒ–æµ‹è¯•
        if func_info['args']:
            lines.extend([
                f'@pytest.mark.parametrize("input_data,expected", [',
                '    # TODO: Add test cases',
                '    (None, None),',
                '])',
                f'def test_{func_name}_parametrized(input_data, expected):',
                f'    """Test {func_name} with different inputs"""',
                '    # TODO: Implement parametrized test',
                '    pass',
                '',
            ])
        
        # é”™è¯¯æƒ…å†µæµ‹è¯•
        lines.extend([
            f'def test_{func_name}_error_case():',
            f'    """Test {func_name} error handling"""',
            '    # TODO: Test error scenarios',
            '    with pytest.raises(Exception):',
            f'        {func_name}(invalid_input)',
            '',
        ])
        
        return lines
    
    def save_test_file(self, output_dir: str = "tests") -> str:
        """ä¿å­˜æµ‹è¯•æ–‡ä»¶"""
        output_path = Path(output_dir)
        
        # åˆ›å»ºç›®å½•ç»“æ„
        relative_path = self.source_file.relative_to(Path.cwd()))
        
        if relative_path.parts[0] == "app":
            # ç§»é™¤appå‰ç¼€ï¼Œå› ä¸ºæµ‹è¯•åœ¨testsç›®å½•ä¸‹
            test_path_parts = relative_path.parts[1:]
        else:
            test_path_parts = relative_path.parts
        
        test_file_name = f"test_{self.source_file.stem}.py"
        test_file_path = output_path / Path(*test_path_parts[:-1]) / test_file_name
        
        # åˆ›å»ºç›®å½•
        test_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆå¹¶ä¿å­˜æµ‹è¯•å†…å®¹
        test_content = self.generate_test_template()
        
        if test_file_path.exists():
            print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶å·²å­˜åœ¨: {test_file_path}")
            print("æ˜¯å¦è¦†ç›–? (y/N): ", end="")
            if input().lower() != 'y':
                return str(test_file_path)
        
        with open(test_file_path, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        print(f"âœ… æµ‹è¯•æ¨¡æ¿å·²ç”Ÿæˆ: {test_file_path}")
        return str(test_file_path)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”Ÿæˆæµ‹è¯•æ¨¡æ¿")
    parser.add_argument("source_file", help="æºä»£ç æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-dir", default="tests", help="æµ‹è¯•æ–‡ä»¶è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    generator = TestGenerator(args.source_file)
    test_file = generator.save_test_file(args.output_dir)
    
    print(f"\nğŸ“ è¯·ç¼–è¾‘ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶å®Œå–„æµ‹è¯•ç”¨ä¾‹:")
    print(f"   {test_file}")

if __name__ == "__main__":
    main()
```

## 5. æ€»ç»“

### 5.1 å®æ–½è·¯çº¿å›¾

#### ç¬¬1é˜¶æ®µï¼šåŸºç¡€è®¾æ–½æ­å»ºï¼ˆ1å‘¨ï¼‰
- [ ] é…ç½®Coverage.pyå’ŒPytest
- [ ] è®¾ç½®CI/CDè¦†ç›–ç‡æ£€æŸ¥
- [ ] åˆ›å»ºè¦†ç›–ç‡ç›‘æ§è„šæœ¬

#### ç¬¬2é˜¶æ®µï¼šè¦†ç›–ç‡æå‡ï¼ˆ2-3å‘¨ï¼‰
- [ ] è¯†åˆ«ä½è¦†ç›–ç‡æ–‡ä»¶
- [ ] ç”Ÿæˆæµ‹è¯•æ¨¡æ¿
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•è¾¾åˆ°80%è¦†ç›–ç‡

#### ç¬¬3é˜¶æ®µï¼šè´¨é‡åº¦é‡ï¼ˆ1å‘¨ï¼‰
- [ ] é›†æˆSonarQubeæˆ–ç±»ä¼¼å·¥å…·
- [ ] è®¾ç½®è´¨é‡é—¨ç¦
- [ ] å»ºç«‹è¦†ç›–ç‡ä»ªè¡¨æ¿

#### ç¬¬4é˜¶æ®µï¼šæŒç»­ä¼˜åŒ–ï¼ˆæŒç»­è¿›è¡Œï¼‰
- [ ] å®šæœŸå®¡æŸ¥è¦†ç›–ç‡æŠ¥å‘Š
- [ ] ä¼˜åŒ–æµ‹è¯•ç­–ç•¥
- [ ] ç»´æŠ¤è´¨é‡æ ‡å‡†

### 5.2 æœ€ä½³å®è·µå»ºè®®

1. **æ¸è¿›å¼æ”¹è¿›**ï¼šä¸è¦è¯•å›¾ä¸€æ¬¡æ€§è¾¾åˆ°100%è¦†ç›–ç‡
2. **è´¨é‡ä¼˜äºæ•°é‡**ï¼šå…³æ³¨æµ‹è¯•çš„æœ‰æ•ˆæ€§è€Œä¸ä»…ä»…æ˜¯è¦†ç›–ç‡æ•°å­—
3. **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**ï¼šå°½å¯èƒ½è‡ªåŠ¨åŒ–è¦†ç›–ç‡æ£€æŸ¥å’ŒæŠ¥å‘Š
4. **å›¢é˜Ÿåä½œ**ï¼šè®©æ‰€æœ‰å¼€å‘è€…éƒ½ç†è§£å’Œå‚ä¸è¦†ç›–ç‡ç»´æŠ¤
5. **æŒç»­ç›‘æ§**ï¼šå»ºç«‹é•¿æœŸçš„è¦†ç›–ç‡è¶‹åŠ¿ç›‘æ§

è¿™å¥—å®Œæ•´çš„æµ‹è¯•è¦†ç›–ç‡ç›‘æ§æ–¹æ¡ˆå°†å¸®åŠ©æ‚¨å»ºç«‹é«˜è´¨é‡çš„ä»£ç åº“ï¼Œç¡®ä¿é¡¹ç›®çš„é•¿æœŸå¯ç»´æŠ¤æ€§å’Œå¯é æ€§ã€‚